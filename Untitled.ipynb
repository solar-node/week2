{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ae4b25c9-b7bd-46b8-ba38-747e8394b0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from IPython.display import Markdown, display, update_display\n",
    "from langchain.schema import SystemMessage, HumanMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d70eb8a4-53f2-487b-a679-cb56f16b8300",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "os.environ['GOOGLE_API_KEY'] = os.getenv('GEMINI_API_KEY')\n",
    "\n",
    "gemini = ChatGoogleGenerativeAI(\n",
    "    model='gemini-1.5-flash',\n",
    "    temperature=0.7,\n",
    "    google_api_key=os.getenv('GEMINI_API_KEY')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "928699a0-b102-46e9-babb-fd510e6fa569",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"You are an assistant that is great at telling jokes\"\n",
    "user_prompt = \"Tell a light hearted joke for an audience of Data Scientist\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "df07fe76-5172-41d4-b2b8-c1517454e100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why was the data scientist sad?  Because they didn't get any arrays.\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    SystemMessage(content=system_message),\n",
    "    HumanMessage(content=user_prompt)\n",
    "]\n",
    "\n",
    "response = gemini.invoke(messages)\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "629c2884-4721-4e0f-8c3b-30237469c2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini2 = ChatGoogleGenerativeAI(\n",
    "    model='gemini-2.5-flash',\n",
    "    temperature=0.7,\n",
    "    google_api_key=os.getenv('GEMINI_API_KEY')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0cd98c6c-4024-4ff4-ab7a-f36d4ed6df06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why did the data scientist break up with the highly accurate but uninterpretable deep learning model?\n",
      "\n",
      "Because even though it predicted everything perfectly, it could never explain *why*!\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    SystemMessage(content=system_message),\n",
    "    HumanMessage(content=user_prompt)\n",
    "]\n",
    "\n",
    "response = gemini2.invoke(messages)\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c77405fc-44c2-453c-ae16-82d9ba986ce1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deciding if an LLM is the right solution for a business problem requires careful consideration.  It's not a silver bullet, and using one inappropriately can be costly and ineffective. Here's a structured approach:\n",
      "\n",
      "**1. Identify the Core Problem:**\n",
      "\n",
      "* **Clearly define the problem:**  What exactly are you trying to solve? Be specific and avoid vague descriptions.  Instead of \"improve customer service,\" try \"reduce customer service call resolution time by 15%.\"\n",
      "* **Quantify the problem:**  Can you measure the impact of the problem?  Quantifiable metrics are crucial for evaluating the success of any solution, including an LLM.  What are the costs associated with the problem? What are the potential benefits of solving it?\n",
      "\n",
      "**2. Assess LLM Suitability:**\n",
      "\n",
      "* **Is the problem text-based?** LLMs excel at processing and generating text. If your problem doesn't involve text (e.g., optimizing a manufacturing process), an LLM is likely not the best fit.\n",
      "* **Does the problem involve understanding, generating, or transforming text?**  Examples include:\n",
      "    * **Understanding:** Summarizing documents, extracting key information, sentiment analysis, classifying text.\n",
      "    * **Generating:** Writing emails, creating reports, translating languages, generating creative content.\n",
      "    * **Transforming:** Paraphrasing, question answering, chatbots.\n",
      "* **Is there sufficient data?** LLMs require large amounts of training data. If you don't have enough relevant data, the model's performance will be limited.\n",
      "* **Is the data high-quality?**  Garbage in, garbage out.  LLMs are only as good as the data they are trained on. Inaccurate, incomplete, or biased data will lead to inaccurate or biased results.\n",
      "* **Can you tolerate some level of inaccuracy?** LLMs are probabilistic models; they don't always produce perfect results.  You need to assess whether the potential inaccuracies are acceptable within the context of your business problem.\n",
      "* **Are there ethical considerations?**  LLMs can perpetuate biases present in their training data.  Consider the potential for bias and how you will mitigate it.  Also consider issues around data privacy and security.\n",
      "* **What is the cost and complexity of implementation?** LLMs can be expensive to implement and require specialized skills to manage and maintain.  Consider the total cost of ownership.\n",
      "\n",
      "**3. Compare to Alternatives:**\n",
      "\n",
      "* **Are there simpler, cheaper solutions?**  Before investing in an LLM, explore simpler alternatives like rule-based systems, keyword search, or traditional machine learning models.  LLMs are often overkill for simpler problems.\n",
      "* **What is the ROI?**  Carefully estimate the potential return on investment (ROI) of using an LLM compared to other solutions.  Will the benefits outweigh the costs?\n",
      "\n",
      "**4.  Pilot and Iterate:**\n",
      "\n",
      "* **Start small:** Begin with a small-scale pilot project to test the feasibility and effectiveness of an LLM solution before deploying it widely.\n",
      "* **Iterate and refine:**  LLMs often require iterative refinement.  Monitor performance, gather feedback, and adjust the model or its parameters as needed.\n",
      "\n",
      "\n",
      "**Examples of Suitable Problems:**\n",
      "\n",
      "* **Automating customer support:** Building a chatbot to answer frequently asked questions.\n",
      "* **Summarizing customer feedback:**  Extracting key insights from customer reviews.\n",
      "* **Generating marketing copy:** Creating engaging ad copy or social media posts.\n",
      "* **Translating documents:** Converting documents between languages.\n",
      "\n",
      "\n",
      "**Examples of Unsuitable Problems:**\n",
      "\n",
      "* **Predicting stock prices:**  LLMs are not designed for time series forecasting.\n",
      "* **Controlling a robotic arm:**  LLMs are not designed for real-time control of physical systems.\n",
      "* **Diagnosing medical conditions:**  LLMs should not be used for tasks requiring high accuracy and reliability.\n",
      "\n",
      "\n",
      "By carefully considering these factors, you can make an informed decision about whether an LLM is the right solution for your business problem. Remember that thorough planning and a phased approach are crucial for success.\n"
     ]
    }
   ],
   "source": [
    "# Now going with the real question\n",
    "system_message = \"You are a helpful assistant\" \n",
    "user_prompt = \"How do I decide if a business problem is suitable for an LLM solution?\"\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=system_message),\n",
    "    HumanMessage(content=user_prompt)\n",
    "]\n",
    "\n",
    "response = gemini.invoke(messages)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "157b7708-0abc-4261-b224-10da496e3112",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Deciding if a business problem is suitable for a Large Language Model (LLM) solution requires careful consideration.  It's not a one-size-fits-all answer, and often involves a nuanced evaluation. Here's a breakdown of factors to consider:\n",
       "\n",
       "**Factors suggesting a good fit for an LLM solution:**\n",
       "\n",
       "* **The problem involves processing or generating text or code:** LLMs excel at tasks like text summarization, translation, question answering, content generation (e.g., marketing copy, email responses), code generation and completion, and sentiment analysis.  If your problem fundamentally involves manipulating or understanding text or code, an LLM is a strong candidate.\n",
       "\n",
       "* **You have a large amount of textual data:** LLMs are trained on massive datasets.  If you have a substantial corpus of text relevant to your problem (e.g., customer reviews, internal documents, research papers), an LLM can leverage this data effectively.\n",
       "\n",
       "* **The problem requires understanding context and nuance:** LLMs are better than traditional rule-based systems at understanding the context and subtleties within text.  For example, identifying sarcasm or understanding the intent behind a customer complaint benefits from an LLM's contextual awareness.\n",
       "\n",
       "* **Automation is desired:** LLMs can automate many tasks that previously required human intervention, such as generating reports, summarizing documents, or answering frequently asked questions.  This can significantly improve efficiency and reduce costs.\n",
       "\n",
       "* **The problem involves ambiguity or creativity:** LLMs can handle ambiguity and generate creative content, unlike rigid rule-based systems.  This is valuable for tasks like brainstorming, content creation, or generating diverse solutions.\n",
       "\n",
       "* **You need rapid prototyping and iteration:** LLMs allow for rapid prototyping and experimentation. You can quickly test different models and approaches to find the best solution for your problem.\n",
       "\n",
       "\n",
       "**Factors suggesting a *poor* fit for an LLM solution:**\n",
       "\n",
       "* **The problem requires real-time, low-latency responses:** LLMs can be computationally expensive and slow, making them unsuitable for applications requiring immediate responses (e.g., real-time chatbots with strict response time requirements).\n",
       "\n",
       "* **The problem requires high accuracy and reliability in critical situations:** While LLMs are improving, they can still generate inaccurate or nonsensical outputs.  They are not suitable for applications where errors have severe consequences (e.g., medical diagnosis, financial transactions).  Thorough validation and human-in-the-loop processes are crucial to mitigate this risk.\n",
       "\n",
       "* **The problem requires reasoning or complex logic beyond the LLM's capabilities:** LLMs are not inherently good at complex reasoning or logical deduction.  They might struggle with problems requiring mathematical calculations, intricate decision-making, or deep causal inference.\n",
       "\n",
       "* **The problem lacks sufficient training data:** LLMs require large amounts of training data. If you don't have enough relevant data, the LLM's performance will be severely limited.\n",
       "\n",
       "* **Ethical considerations are paramount:** LLMs can generate biased or harmful content.  Careful consideration of ethical implications and mitigation strategies is essential, especially when dealing with sensitive data or topics.\n",
       "\n",
       "* **The cost is prohibitive:**  Using LLMs can be expensive, especially for large-scale deployments.  The cost of computation, data storage, and API access needs careful evaluation.\n",
       "\n",
       "\n",
       "**In summary:**  Before committing to an LLM solution, carefully analyze your business problem, assess the availability of relevant data, consider the potential risks and ethical implications, and evaluate the cost-benefit ratio.  A thorough understanding of LLM capabilities and limitations is crucial for making an informed decision.  Often, a hybrid approach combining LLMs with other technologies might be the optimal solution."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show in streaming form\n",
    "response_text = \"\"\n",
    "display_handle = display(Markdown(\"\"), display_id = True)\n",
    "\n",
    "for chunk in gemini.stream(messages):\n",
    "    if chunk.content:\n",
    "        response_text += chunk.content\n",
    "         #clean formatting if needed\n",
    "        clean_text = response_text.replace(\"```\", \"\").replace(\"markdown\", \"\")\n",
    "        update_display (Markdown(clean_text), display_id = display_handle.display_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd9a303-fe3b-4c81-a63e-0d023d998028",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
